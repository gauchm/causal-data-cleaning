{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge extraction dataset\n",
    "In this dataset, we have extracted tuples `arg1, relation, arg2` with confidence scores. We add POS-tags as additional dimensions.\n",
    "\n",
    "Data source: http://reverb.cs.washington.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import string_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'woe_parse'\n",
    "extractions = pd.read_csv('data/reverb_emnlp2011_data/extractions/{}.txt'.format(filename), sep='\\t', header=None)\n",
    "extractions.columns = ['id', 'arg1', 'relation', 'arg2', 'confidence']\n",
    "\n",
    "# The original sentences\n",
    "sentences = pd.read_csv('data/reverb_emnlp2011_data/sentences.txt', sep='\\t', header=None)\n",
    "sentences.columns = ['sentenceId', 'sentence']\n",
    "\n",
    "# Correctness labels\n",
    "labels = pd.read_csv('data/reverb_emnlp2011_data/labels.txt', sep='\\t', header=None)\n",
    "labels.columns = ['truth', 'sentenceId', 'arg1', 'relation', 'arg2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We add POS-tags to `arg1`, `relation` and `arg2` by tagging the original sentence and searching for the extracted tokens in the tagged sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['tokenized'] = sentences['sentence'].apply(nltk.word_tokenize)\n",
    "sentences['tagged'] = sentences['tokenized'].apply(lambda x: nltk.pos_tag(x, tagset='universal'))\n",
    "\n",
    "extractions = extractions.merge(labels, on=['sentenceId', 'arg1', 'relation', 'arg2'], how='inner')\n",
    "extractions = extractions.merge(sentences, on='sentenceId', how='left')\n",
    "\n",
    "extractions['tokenized-arg1'] = extractions['arg1'].apply(nltk.word_tokenize)\n",
    "extractions['tokenized-relation'] = extractions['relation'].apply(nltk.word_tokenize)\n",
    "extractions['tokenized-arg2'] = extractions['arg2'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring 52 tuples\n"
     ]
    }
   ],
   "source": [
    "old_shape = extractions.shape[0]\n",
    "\n",
    "extractions['tagged-arg1'] = extractions.apply(lambda t: string_utils.find_subsequence(t['tokenized'], t['tokenized-arg1'], t['tagged']), axis=1)\n",
    "extractions['tagged-relation'] = extractions.apply(lambda t: string_utils.find_subsequence(t['tokenized'], t['tokenized-relation'], t['tagged']), axis=1)\n",
    "extractions['tagged-arg2'] = extractions.apply(lambda t: string_utils.find_subsequence(t['tokenized'], t['tokenized-arg2'], t['tagged']), axis=1)\n",
    "\n",
    "# Remove tuples where we couldn't find all POS tags\n",
    "extractions = extractions[extractions['tokenized-arg1'].apply(len) == extractions['tagged-arg1'].apply(len)]\n",
    "extractions = extractions[extractions['tokenized-relation'].apply(len) == extractions['tagged-relation'].apply(len)]\n",
    "extractions = extractions[extractions['tokenized-arg2'].apply(len) == extractions['tagged-arg2'].apply(len)]\n",
    "\n",
    "print('Ignoring {} tuples'.format(old_shape - extractions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting for Data X-Ray\n",
    "Now, we format the tuples such that they can be read by Data X-Ray to find a cause assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>arg1</th>\n",
       "      <th>relation</th>\n",
       "      <th>arg2</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_0.6_:</td>\n",
       "      <td>a_PRON_they_:</td>\n",
       "      <td>a_VERB_plan-raise_:</td>\n",
       "      <td>a_NOUN_premiums_:</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_0.6_:</td>\n",
       "      <td>a_PRON_they_:</td>\n",
       "      <td>a_VERB_plan-reduce_:</td>\n",
       "      <td>a_NOUN_benefits_:</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_0.7_:</td>\n",
       "      <td>a_ADJ-NOUN-PRT-DET_The-two-year-note-'s-yield_:</td>\n",
       "      <td>a_ADJ-VERB-ADP_was-unchanged-at_:</td>\n",
       "      <td>a_NOUN-NUM_5.95-percent_:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_0.9_:</td>\n",
       "      <td>a_DET-NUM_The-12_:</td>\n",
       "      <td>a_VERB_is_:</td>\n",
       "      <td>a_.-NUM_$-70.00_:</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_0.9_:</td>\n",
       "      <td>a_ADJ-NOUN-DET_The-principal-opposition-parties_:</td>\n",
       "      <td>a_VERB_boycotted_:</td>\n",
       "      <td>a_NOUN-DET_the-polls_:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  confidence                                               arg1  \\\n",
       "0    a_0.6_:                                      a_PRON_they_:   \n",
       "1    a_0.6_:                                      a_PRON_they_:   \n",
       "2    a_0.7_:    a_ADJ-NOUN-PRT-DET_The-two-year-note-'s-yield_:   \n",
       "3    a_0.9_:                                 a_DET-NUM_The-12_:   \n",
       "4    a_0.9_:  a_ADJ-NOUN-DET_The-principal-opposition-parties_:   \n",
       "\n",
       "                            relation                       arg2  truth  \n",
       "0                a_VERB_plan-raise_:          a_NOUN_premiums_:      0  \n",
       "1               a_VERB_plan-reduce_:          a_NOUN_benefits_:      0  \n",
       "2  a_ADJ-VERB-ADP_was-unchanged-at_:  a_NOUN-NUM_5.95-percent_:      1  \n",
       "3                        a_VERB_is_:          a_.-NUM_$-70.00_:      0  \n",
       "4                 a_VERB_boycotted_:     a_NOUN-DET_the-polls_:      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractions['pos-arg1'] = extractions['tagged-arg1'].apply(lambda t: set(list(x[1] for x in t)))\n",
    "extractions['pos-relation'] = extractions['tagged-relation'].apply(lambda t: set(list(x[1] for x in t)))\n",
    "extractions['pos-arg2'] = extractions['tagged-arg2'].apply(lambda t: set(list(x[1] for x in t)))\n",
    "\n",
    "extractions.head()\n",
    "\n",
    "out = extractions[['confidence', 'pos-arg1', 'pos-relation', 'pos-arg2', 'tokenized-arg1', 'tokenized-relation', 'tokenized-arg2', 'truth']].copy()\n",
    "out['confidence'] = 'a_' + out['confidence'].round(1).astype(str) + '_:'\n",
    "out['arg1'] = 'a_' + out['pos-arg1'].apply(lambda x: '-'.join(x)) + '_' + out['tokenized-arg1'].apply(lambda x: '-'.join(x)) + '_:'\n",
    "out['relation'] = 'a_' + out['pos-relation'].apply(lambda x: '-'.join(x)) + '_' + out['tokenized-relation'].apply(lambda x: '-'.join(x)) + '_:'\n",
    "out['arg2'] = 'a_' + out['pos-arg2'].apply(lambda x: '-'.join(x)) + '_' + out['tokenized-arg2'].apply(lambda x: '-'.join(x)) + '_:'\n",
    "\n",
    "out = out[['confidence', 'arg1', 'relation', 'arg2', 'truth']]\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:a:a:a:\\t1:2:2:2:;0.37876960193003617;0.0;false;a:a:a:a:;1:1:1:1:;829;0;'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = 'a:a:a:a:'\n",
    "structure_vector = '1:1:1:1:'\n",
    "max_dims = '1:2:2:2:'\n",
    "error_rate = out['truth'].mean()\n",
    "cost = 0.0\n",
    "\n",
    "top_row = feature_vector + '\\t' + max_dims + ';' + str(error_rate) + ';' + str(cost) + ';false;' + feature_vector + ';' + structure_vector + ';' + str(len(out)) + ';0;'\n",
    "top_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['input-str'] = out['confidence'] + out['arg1'] + out['relation'] + out['arg2']\n",
    "out['truth'] = out['truth'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Data X-Ray input file\n",
    "with open('./data/{}-posAsSet-input.txt'.format(filename), 'w') as f:\n",
    "    f.write(top_row)\n",
    "    list(f.write('{}%{}%{}='.format(i, out['truth'].iloc[i], out['input-str'].iloc[i])) for i in range(len(out)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
